layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00800000037998
    mirror: false 
    mean_value: 72
    mean_value: 83
    mean_value: 73
  }
  image_data_param {
    source: "/home/vip/dataset/cityscapes/img_val_1024x2048_list.txt"
    batch_size: 1
    shuffle: false
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "res2.1.conv1"
  type: "Convolution"
  bottom: "conv2"
  top: "res2.1.conv1"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2.1.conv1/relu"
  type: "ReLU"
  bottom: "res2.1.conv1"
  top: "res2.1.conv1"
}
layer {
  name: "res2.1.conv2"
  type: "Convolution"
  bottom: "res2.1.conv1"
  top: "res2.1.conv2"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "res2.1.skipConv"
  type: "Convolution"
  bottom: "conv2"
  top: "res2.1.skipConv"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "res2.1.sum"
  type: "Eltwise"
  bottom: "res2.1.conv2"
  bottom: "res2.1.skipConv"
  top: "res2.1.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res2.1.relu"
  type: "ReLU"
  bottom: "res2.1.sum"
  top: "res2.1.sum"
}
layer {
  name: "res2.2.conv1"
  type: "Convolution"
  bottom: "res2.1.sum"
  top: "res2.2.conv1"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "res2.2.conv1/relu"
  type: "ReLU"
  bottom: "res2.2.conv1"
  top: "res2.2.conv1"
}
layer {
  name: "res2.2.conv2"
  type: "Convolution"
  bottom: "res2.2.conv1"
  top: "res2.2.conv2"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "res2.2.sum"
  type: "Eltwise"
  bottom: "res2.2.conv2"
  bottom: "res2.1.sum"
  top: "res2.2.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res2.2.relu"
  type: "ReLU"
  bottom: "res2.2.sum"
  top: "res2.2.sum"
}
layer {
  name: "res3.1.conv1"
  type: "Convolution"
  bottom: "res2.2.sum"
  top: "res3.1.conv1"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res3.1.conv1/relu"
  type: "ReLU"
  bottom: "res3.1.conv1"
  top: "res3.1.conv1"
}
layer {
  name: "res3.1.conv2"
  type: "Convolution"
  bottom: "res3.1.conv1"
  top: "res3.1.conv2"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "res3.1.skipConv"
  type: "Convolution"
  bottom: "res2.2.sum"
  top: "res3.1.skipConv"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "res3.1.sum"
  type: "Eltwise"
  bottom: "res3.1.conv2"
  bottom: "res3.1.skipConv"
  top: "res3.1.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res3.1.relu"
  type: "ReLU"
  bottom: "res3.1.sum"
  top: "res3.1.sum"
}
layer {
  name: "res3.2.conv1"
  type: "Convolution"
  bottom: "res3.1.sum"
  top: "res3.2.conv1"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "res3.2.conv1/relu"
  type: "ReLU"
  bottom: "res3.2.conv1"
  top: "res3.2.conv1"
}
layer {
  name: "res3.2.conv2"
  type: "Convolution"
  bottom: "res3.2.conv1"
  top: "res3.2.conv2"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "res3.2.sum"
  type: "Eltwise"
  bottom: "res3.2.conv2"
  bottom: "res3.1.sum"
  top: "res3.2.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res3.2.relu"
  type: "ReLU"
  bottom: "res3.2.sum"
  top: "res3.2.sum"
}
layer {
  name: "res4.1.conv1"
  type: "Convolution"
  bottom: "res3.2.sum"
  top: "res4.1.conv1"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res4.1.conv1/relu"
  type: "ReLU"
  bottom: "res4.1.conv1"
  top: "res4.1.conv1"
}
layer {
  name: "res4.1.conv2"
  type: "Convolution"
  bottom: "res4.1.conv1"
  top: "res4.1.conv2"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "res4.1.skipConv"
  type: "Convolution"
  bottom: "res3.2.sum"
  top: "res4.1.skipConv"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "res4.1.sum"
  type: "Eltwise"
  bottom: "res4.1.conv2"
  bottom: "res4.1.skipConv"
  top: "res4.1.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4.1.relu"
  type: "ReLU"
  bottom: "res4.1.sum"
  top: "res4.1.sum"
}
layer {
  name: "res4.2.conv1"
  type: "Convolution"
  bottom: "res4.1.sum"
  top: "res4.2.conv1"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "res4.2.conv1/relu"
  type: "ReLU"
  bottom: "res4.2.conv1"
  top: "res4.2.conv1"
}
layer {
  name: "res4.2.conv2"
  type: "Convolution"
  bottom: "res4.2.conv1"
  top: "res4.2.conv2"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "res4.2.skipConv"
  type: "Convolution"
  bottom: "res4.1.sum"
  top: "res4.2.skipConv"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4.2.sum"
  type: "Eltwise"
  bottom: "res4.2.conv2"
  bottom: "res4.2.skipConv"
  top: "res4.2.sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4.2.relu"
  type: "ReLU"
  bottom: "res4.2.sum"
  top: "res4.2.sum"
}
layer {
  name: "psp.pool1"
  type: "Pooling"
  bottom: "res4.2.sum"
  top: "psp.pool1"
  pooling_param {
    pool: AVE
    kernel_size: 32
    stride: 32
  }
}
layer {
  name: "psp.pool1.conv"
  type: "Convolution"
  bottom: "psp.pool1"
  top: "psp.pool1.conv"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "psp.pool1.conv/relu"
  type: "ReLU"
  bottom: "psp.pool1.conv"
  top: "psp.pool1.conv"
}
layer {
  name: "psp.pool1.interp"
  type: "Interp"
  bottom: "psp.pool1.conv"
  top: "psp.pool1.interp"
  include {
    phase: TRAIN
  }
  interp_param {
    height: 32
    width: 32
  }
}
layer {
  name: "psp.pool1.interp"
  type: "Interp"
  bottom: "psp.pool1.conv"
  top: "psp.pool1.interp"
  include {
    phase: TEST
  }
  interp_param {
    height: 32
    width: 64
  }
}
layer {
  name: "psp.pool2"
  type: "Pooling"
  bottom: "res4.2.sum"
  top: "psp.pool2"
  pooling_param {
    pool: AVE
    kernel_size: 16
    stride: 16
  }
}
layer {
  name: "psp.pool2.conv"
  type: "Convolution"
  bottom: "psp.pool2"
  top: "psp.pool2.conv"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "psp.pool2.conv/relu"
  type: "ReLU"
  bottom: "psp.pool2.conv"
  top: "psp.pool2.conv"
}
layer {
  name: "psp.pool2.interp"
  type: "Interp"
  bottom: "psp.pool2.conv"
  top: "psp.pool2.interp"
  include {
    phase: TRAIN
  }
  interp_param {
    height: 32
    width: 32
  }
}
layer {
  name: "psp.pool2.interp"
  type: "Interp"
  bottom: "psp.pool2.conv"
  top: "psp.pool2.interp"
  include {
    phase: TEST
  }
  interp_param {
    height: 32
    width: 64
  }
}
layer {
  name: "psp.pool3"
  type: "Pooling"
  bottom: "res4.2.sum"
  top: "psp.pool3"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "psp.pool3.conv"
  type: "Convolution"
  bottom: "psp.pool3"
  top: "psp.pool3.conv"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "psp.pool3.conv/relu"
  type: "ReLU"
  bottom: "psp.pool3.conv"
  top: "psp.pool3.conv"
}
layer {
  name: "psp.pool3.interp"
  type: "Interp"
  bottom: "psp.pool3.conv"
  top: "psp.pool3.interp"
  include {
    phase: TRAIN
  }
  interp_param {
    height: 32
    width: 32
  }
}
layer {
  name: "psp.pool3.interp"
  type: "Interp"
  bottom: "psp.pool3.conv"
  top: "psp.pool3.interp"
  include {
    phase: TEST
  }
  interp_param {
    height: 32
    width: 64
  }
}
layer {
  name: "psp.pool4"
  type: "Pooling"
  bottom: "res4.2.sum"
  top: "psp.pool4"
  pooling_param {
    pool: AVE
    kernel_size: 4
    stride: 4
  }
}
layer {
  name: "psp.pool4.conv"
  type: "Convolution"
  bottom: "psp.pool4"
  top: "psp.pool4.conv"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "psp.pool4.conv/relu"
  type: "ReLU"
  bottom: "psp.pool4.conv"
  top: "psp.pool4.conv"
}
layer {
  name: "psp.pool4.interp"
  type: "Interp"
  bottom: "psp.pool4.conv"
  top: "psp.pool4.interp"
  include {
    phase: TRAIN
  }
  interp_param {
    height: 32
    width: 32
  }
}
layer {
  name: "psp.pool4.interp"
  type: "Interp"
  bottom: "psp.pool4.conv"
  top: "psp.pool4.interp"
  include {
    phase: TEST
  }
  interp_param {
    height: 32
    width: 64
  }
}
layer {
  name: "psp.concat"
  type: "Concat"
  bottom: "res4.2.sum"
  bottom: "psp.pool1.interp"
  bottom: "psp.pool2.interp"
  bottom: "psp.pool3.interp"
  bottom: "psp.pool4.interp"
  top: "psp.concat"
}
layer {
  name: "psp.concat.conv"
  type: "Convolution"
  bottom: "psp.concat"
  top: "psp.concat.conv"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "psp.concat.conv/relu"
  type: "ReLU"
  bottom: "psp.concat.conv"
  top: "psp.concat.conv"
}
layer {
  name: "Decoder_wc3"
  type: "Convolution"
  bottom: "res2.2.sum"
  top: "Decoder_wc3"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "Decoder_wc3/relu"
  type: "ReLU"
  bottom: "Decoder_wc3"
  top: "Decoder_wc3"
}
layer {
  name: "Decoder_wc4"
  type: "Convolution"
  bottom: "res3.2.sum"
  top: "Decoder_wc4"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "Decoder_wc4/relu"
  type: "ReLU"
  bottom: "Decoder_wc4"
  top: "Decoder_wc4"
}
layer {
  name: "Decoder_wc5"
  type: "Convolution"
  bottom: "psp.concat.conv"
  top: "Decoder_wc5"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "Decoder_wc5/relu"
  type: "ReLU"
  bottom: "Decoder_wc5"
  top: "Decoder_wc5"
}
layer {
  name: "Decoder4_4.proj"
  type: "Convolution"
  bottom: "Decoder_wc5"
  top: "Decoder4_4.proj"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "Decoder4_4.proj/relu"
  type: "ReLU"
  bottom: "Decoder4_4.proj"
  top: "Decoder4_4.proj"
}
layer {
  name: "Decoder4_4.proj/up2"
  type: "Deconvolution"
  bottom: "Decoder4_4.proj"
  top: "Decoder4_4.proj/up2"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 4
    stride: 2
	group: 32
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "Decoder4_4.concat"
  type: "Concat"
  bottom: "Decoder_wc4"
  bottom: "Decoder4_4.proj/up2"
  top: "Decoder4_4.concat"
}
layer {
  name: "Decoder4_4.conv1"
  type: "Convolution"
  bottom: "Decoder4_4.concat"
  top: "Decoder4_4.conv1"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Decoder4_4.conv1/relu"
  type: "ReLU"
  bottom: "Decoder4_4.conv1"
  top: "Decoder4_4.conv1"
}
layer {
  name: "Decoder3_3.proj"
  type: "Convolution"
  bottom: "Decoder4_4.conv1"
  top: "Decoder3_3.proj"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "Decoder3_3.proj/relu"
  type: "ReLU"
  bottom: "Decoder3_3.proj"
  top: "Decoder3_3.proj"
}
layer {
  name: "Decoder3_3.proj/up2"
  type: "Deconvolution"
  bottom: "Decoder3_3.proj"
  top: "Decoder3_3.proj/up2"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 4
    stride: 2
	group: 32
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "Decoder3_3.concat"
  type: "Concat"
  bottom: "Decoder_wc3"
  bottom: "Decoder3_3.proj/up2"
  top: "Decoder3_3.concat"
}
layer {
  name: "Decoder3_3.conv1"
  type: "Convolution"
  bottom: "Decoder3_3.concat"
  top: "Decoder3_3.conv1"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Decoder3_3.conv1/relu"
  type: "ReLU"
  bottom: "Decoder3_3.conv1"
  top: "Decoder3_3.conv1"
}
layer {
  name: "Decoder_score"
  type: "Convolution"
  bottom: "Decoder3_3.conv1"
  top: "Decoder_score"
  convolution_param {
    num_output: 19
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Decoder_score.up8"
  type: "Deconvolution"
  bottom: "Decoder_score"
  top: "Decoder_score.up8"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 19
    bias_term: false
    pad: 4
    kernel_size: 16
    stride: 8
	group: 19
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "Decoder_score.up8"
  top: "prob"
  include {
    phase: TEST
  }
}
layer {
  name: "pred"
  type: "ArgMax"
  bottom: "prob"
  top: "pred"
  include {
    phase: TEST
  }
  argmax_param {
    axis: 1
  }
}
layer {
  name: "prob_d8"
  type: "Softmax"
  bottom: "Decoder_score"
  top: "prob_d8"
  include {
    phase: TEST
  }
}
layer {
  name: "pred_d8"
  type: "ArgMax"
  bottom: "prob_d8"
  top: "pred_d8"
  include {
    phase: TEST
  }
  argmax_param {
    axis: 1
  }
}
